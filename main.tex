\documentclass[11pt]{article}
\usepackage[a4paper, hmargin={2.8cm, 2.8cm}, vmargin={2.5cm, 2.5cm}]{geometry}
\usepackage{eso-pic} % \AddToShipoutPicture
\usepackage{graphicx} % \includegraphics
\usepackage{minted}
\usepackage{listings}                 % Source code printer for LaTeX
\usepackage{caption}

%% Change `ku-farve` to `nat-farve` to use SCIENCE's old colors or
%% `natbio-farve` to use SCIENCE's new colors and logo.
\def \ColourPDF {include/natbio-farve}

%% Change `ku-en` to `nat-en` to use the `Faculty of Science` header
\def \TitlePDF   {include/nat-en}  % University of Copenhagen

\title{
  \vspace{3cm}
  \Huge{A WebAssembly Backend for Futhark} \\
  \Large{Msc Thesis}
}

\author{
  \Large{Philip Lassen}
  \\ \texttt{philiplassen@gmail.com} \\
}

\date{
    \today
}

\begin{document}


\AddToShipoutPicture*{\put(0,0){\includegraphics*[viewport=0 0 700 600]{\ColourPDF}}}
\AddToShipoutPicture*{\put(0,602){\includegraphics*[viewport=0 600 700 1600]{\ColourPDF}}}

\AddToShipoutPicture*{\put(0,0){\includegraphics*{\TitlePDF}}}

\clearpage\maketitle
\thispagestyle{empty}

\newpage

%% Write your dissertation here.

\begin{abstract}
More and more general purpose software runs in the browser and in order to exploit advances in parallel processing capabilities of modern computer hardware it is advantageous to invoke parallel programming in the browser, and do it with a high level programming language without the need for domain knowledge, memory safety, etc.
\end{abstract}


\newpage
\tableofcontents
\newpage

\section{Introduction}

\section{Background}

\section{WASM}

\newpage


\section{WASM backend Implementation}

\newpage





\section{Parallel Execution in the Browser}



JavaScript is single threaded. Meaning it consists of a single call stack and a single memory heap. This is slightly counter intuitive as idiomatic JavaScript often contains many asynchronous function calls. Asynchronous function calls are achieved by placing promises/callbacks into an event queue, which runs after the main thread has finished processing. This way they avoid blocking synchronous JavaScript code from running. 

There are three primitives used for doing multithreaded programming in the browser: Web Workers, Shared Memory, and Atomics. These features will be introduced in this section along with examples illustrating how they are used in practice. 


\subsection{Web Workers}
Parallelism with JavaScript in browsers is achieved through web workers. Web workers are extra threads of execution beyond the main thread. The threads interact via message passing. Typically messages are passed through the postMessage and onmessage. postMessage is used to send a message between threads and onmessage works as an event handler to receive messages from threads. 


Web workers are relatively heavyweight, and should not be created in large numbers. They are expected to be long lived and have both high start and high per instance memory cost. 
TODO show why/where this information comes from (FOLLOW UP FROM ABOVE)

The following example computes the Riemann integral of sine over an interval from 0. The interval is broken up into subintervals which are computed by separate workers.

\begin{listing}[H] 
        \inputminted[fontsize=\small,baselinestretch=0.5,linenos]{javascript}{code/worker/integrate.js}
        \caption{Main file that calls workers which compute prefix sum using shared memory and atomics in parallel} 
        
        \label{lst:integrate-js}    
\end{listing} 

The example code in Listing \ref{lst:integrate-js} spawns 4 worker threads in lines 5-7. It sends each thread a message with their respective index in lines 18-20. It asynchronously waits for messages from each of the worker threads with their partial result and prints the final result when all the threads have sent a message in lines 10-16.
\begin{listing}[H] 
        \inputminted[fontsize=\small,baselinestretch=0.5,linenos]{javascript}{code/worker/worker.js}
        \caption{Main file that calls workers which compute prefix sum using shared memory and atomics in parallel} 
        \label{lst:worker-js}    
\end{listing}    
%\captionof{listing}{This is a worker}

The code in Listing \ref{lst:worker-js} contains the implementation of the worker threads. Once the thread receives a message from the main thread with their index, they compute the partial Riemann integral over their respective quartile of the interval adding the value of sine(x) as many times as specified by granularity. 


%Web workers provide a clean and simple interface for web programmers to launch threads for parallel computation in the browser. However there are some problems that benefit from and need additional constructs for parallel execution. An example of this would be problems that benefit from in place array updates. 
%A web server needs to be launched in order to run this example in a browser. The simplest way to get this up and running is to run \texttt{python3 -m http.server 8000} in the directory with the source files.  And then opening \texttt{http://localhost:8000/integrate.html} in the browser.
%Using chrome on a macbook pro the example took approximately 18 seconds to execute and produce the results shown in figure TODO.
%TODO put screenshot
%TODO: Explain how web workers are executed by browser engines; More details on how the example uses web workers and the communication between UI thread and worker threads.


\subsection{Shared Memory and Atomics}

Web workers with message passing have some similarities in how parallelism is executed with the Erlang programming language. Both of which use message passing to coordinate parallel execution. However many other programming languages and libraries also support and utilize shared memory. An example of this is C/C++ and POSIX threads. Shared memory maps closely to modern multicore hardware, and is faster for certain workloads (TODO GIVE EXAMPLE). However it comes at the cost of a new set of bugs in the shape of data races, which is why languages such as Erlang and Futhark itself abstracts the construct away from the programmer.


JavaScript also offers shared memory through SharedArrayBuffers. A SharedArrayBuffer points to a piece of linear memory. The SharedArrayBuffer can be passed to multiple web workers who can access the memory in parallel. 

In principle safe access to shared memory can be coordinated with message passing, but it's far more efficient for fine grained synchronization to use atomic operations, which again map efficiently to the underlying hardware. Atomic operations make sure that predictable values are written and read, that operations are finished before the next operation starts and that operations are not interrupted (TODO cite Atomics Javascript page). The Atomics package in JavaScript contains functions for performing atomic operations on SharedArrayBuffers. The Atomics package also includes wait and notify functions, like linux futex wait and wake.

To illustrate shared memory and atomics the following example is an implementation of prefix sum. It is a fundamental parallel algorithm which is used as a building block for many other parallel algorithms. The example implements the shared memory 2 pass algorithm from (TODO). 
\begin{listing}[H]    
        \inputminted[fontsize=\small,baselinestretch=0.5,linenos]{javascript}{code/shared/main.js}
        \caption{Main file that calls workers which compute prefix sum using shared memory and atomics in parallel}    
        \label{lst:main-js}    
\end{listing}    

The code in Listing \ref{lst:main-js} spawns 9 worker threads. It sends a message to each of the threads with parameters, some of which are shared array buffers. This allows each of the threads to have access to shared memory. When each thread has sent a message to indicate completion, the final result of prefix sum is logged to the console.

%\captionof{listing}{Example of a worker working}
\begin{listing}[H]    
\inputminted[fontsize=\small,baselinestretch=0.5,linenos]{javascript}{code/shared/prefix_sum.js}
        \caption{Worker file for computing the prefix sum using shared memory and atomics.}    
        \label{lst:prefixsum-js}    
\end{listing}    

The code in Listing \ref{lst:prefixsum-js} handles the actual execution of prefix sum. In the first pass the threads



\subsection{Threaded WebAssembly}
There is a proposal to extend the WASM specification with support for threads, namely by leveraging web workers, shared memory, and atomics. Chrome and Firefox and Node.js all have experimental support for threaded WASM. Emscripten supports compilation of C/C++ with pthreads to threaded WASM.

Threaded WASM uses web workers to create and join threads by calling out to JavaScript. Shared memory is accomplished with SharedArrayBuffer, which integrates with WASM's paged memory model. WASM is extended with atomic operation instructions. Putting it concisely the additions of supporting shared array buffers in WASM and adding atomic operations in WASM was all that was needed to facilitate threaded WASM.

A key observation is that WASM does not natively allow for spawning of threads. This is actually taken care of by the runtime or compiler. Specifically for Emscripten, compiling C code written with pthreads will generate three files. It will generate a WASM file, and Javascript glue code. The glue code takes care of loading the WASM module, populating the memory with the required values, and integrating with the host system as the C code would expect. The C function Pthread\_create is translated to Javascript and not WASM. It instead launches a Javascript Worker, passing it a shared array buffer and the wasm module that it should run. Where the WASM simply needs the shared array buffer and atomics to synchronize.  


TODO: Explain the chrome developer video

TODO: Small C example with Pthreads -> find relevant compiled WASM instructinos to use as illustrati

\newpage

\section{WASM Multicore Implementation}


Fortunately only small adaptions had to be made to the WASM backend developed earlier, to get it running with Multicore. The futhark Compiler has a backend that generates both Sequential C code as well as a backend that generates multicore C code using POSIX threads. As discussed Emscripten can translate multicore C code that uses POSIX threads to multicore WASM that can run in parallel in the browser. 

The main advantage of leveraging the WASM backend is that any changes in the API, should stay consistent between the WASM and WASM-Multicore backends (TODO: TALK ABOUT SHARED RUNTIME). Futhark offers 4 backends that generate C code, and 2 backends that generate Python code. In all these cases the API's for the target language are consistent. 


This is greatly beneficial as one of the biggest advantages of Futhark over general use programming languages is that as long as the programmer writes idiomatic Futhark they do not need to concern themselves with the low level details of how Futhark parallelizes their code. 



\subsection{Implementation Structure}

Below we discuss how to add a new futhark backend that can be invoked from the command line with \texttt{futhark wasm-multicore}. It is structured very similarly to the plain wasm backend described chapter 2. Instead of calling Emscripten on the Sequential C, we apply it to futhark's multicore C backend. We utilize the wasm runtime code written in chapter 2, for the backend and add the necessary Emscripten compiler flags required to enable Multicore WASM. Figure (TBD) illustrates the structure of the WASM multicore implementation.

\begin{verbatim}
    
Diagram   
                                       EMCC
Futhark src -> Futhark IR -> C           ->                    -> (1.js, 1.wasm)
                             Multicore C ->                    -> (2.js, 1.wasm)
                                               SHARED JS CODE
\end{verbatim}

One of the key differences that can be seen in the figure is that the wasm-multicore backend produes 2 javascript files and 1 Wasm file as opposed to the Sequential Wasm backend which generates 1 JavaScript file and 1 WASM file. The second file is the web worker file, which is used to launch threads that run WASM, allowing for the desired multi-threaded computation.

\subsection{Implementation Details}
Here we discuss the series of steps that were needed complete the implementation.
\subsubsection{Actions}
Following the same process as the sequential WASM backend we simply need to define a compile program function that takes the C code generated from the Multicore C backend and
\subsubsection{Headers}
Changes to the generated Multicore C


\subsubsection{Emscripten Invocation}
Emscripten Flags (specific to multicore)

\subsubsection{Running in browser with HTTP}
Setting HTTP headers


\subsection{Benchmark}




\subsection{Design Decisions}
\begin{itemize}
    \item Compiler Flags
    \item Setting Memory vs Allow Memory Growth
\end{itemize}

\section{Conclusion}

\end{document}
